{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Strip HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['ClapCount_Card', 'ClapCount_Story', 'Company', 'CompanyURL', 'PostID',\n",
    "#        'PublishedDate', 'ReadingTime', 'ResponseNum_Card', 'ResponseNum_Story',\n",
    "#        'StoryHTML', 'StoryIndex', 'StoryTitle', 'StoryURL', 'StoryURL_Story',\n",
    "#        'Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5', 'TagSource', 'User', 'UserURL',\n",
    "#        'VoterCount', 'isPaywall']\n",
    "\n",
    "\n",
    "cols = ['ClapCount_Card', 'ClapCount_Story', 'Company', 'CompanyURL', 'PostID',\n",
    "       'PublishedDate', 'ReadingTime', 'ResponseNum_Card', 'ResponseNum_Story',\n",
    "       'StoryIndex', 'StoryTitle', 'StoryURL', 'StoryURL_Story',\n",
    "       'Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5', 'TagSource', 'User', 'UserURL',\n",
    "       'VoterCount', 'isPaywall']\n",
    "import pandas as pd\n",
    "reader = pd.read_csv('df_story.csv', chunksize=20000)\n",
    "for chunk in reader:\n",
    "    chunk.to_csv('df_noHTML.csv', index=False, header=False, mode='a')\n",
    "\n",
    "    result = chunk\n",
    "    result['StoryHTML'] = ''\n",
    "\n",
    "    result.to_csv('df_noHTML.csv', index=False, header=False, mode='a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noHTML = pd.read_csv(\"df_noHTML.csv\", names=cols)\n",
    "display(HTML(df_noHTML.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and filter N/A stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-b666bf274d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/df_story_chunk1.csv\", nrows=100)\n",
    "df.head()\n",
    "df = df[-df['PostID'].isnull()]\n",
    "df = df[-df['ReadingTime'].isnull()]\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "9995    False\n",
       "9996    False\n",
       "9997    False\n",
       "9998    False\n",
       "9999    False\n",
       "Name: PostID, Length: 10000, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(df.tail().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text from raw HTML\n",
    "def extract_features_from_html(data):\n",
    "    if pd.notnull(data['StoryHTML']):\n",
    "               \n",
    "        # Using beautifulsoup        \n",
    "        soup = BeautifulSoup(data['StoryHTML'])\n",
    "        \n",
    "        \n",
    "        # Extract num. images\n",
    "        img_count = int(len(soup.find_all(\"img\")))\n",
    "\n",
    "        \n",
    "        # Header information (author / title) is stored in <div> tag with no classname attribute\n",
    "        # It is also the second section tag\n",
    "        featured_image = False\n",
    "        \n",
    "        header = soup.find_all(\"section\") # Header is the second section\n",
    "        if len(header)>=2:\n",
    "            if header[1].find_all(\"img\", {\"role\":\"presentation\"}):\n",
    "                featured_image = True\n",
    "\n",
    "        # First <div> tag is the article itself, remove every other <div> afterwards\n",
    "        headerDivs = soup.find_all(\"div\", {'class':None})\n",
    "        if (headerDivs):  \n",
    "            for div in headerDivs[1:]:\n",
    "                div.decompose()\n",
    "        \n",
    "        # Extract Text\n",
    "        text = soup.text\n",
    "        \n",
    "        # Extract num. words\n",
    "        word_count = int(len(soup.text.split()))\n",
    "        \n",
    "        # Extract code\n",
    "        # There are four ways that authors display code in a Medium article, the first two are retrievable.\n",
    "        # 1) Codeblock: Use ``` ``` which is converted into <pre> tag. Available in data.\n",
    "        # 2) Inline: <code> tag. Available in data.\n",
    "        # 3) Import a Gist file. N/A in data since Gists are embedded content which are not captured by Scrapy and would require a deeper request level.\n",
    "        # 4) Show it as an image. N/A in data since there is no distinguishing tag for \"code\" images and normal images.\n",
    "        \n",
    "        \n",
    "        # Extract num. code blocks that use the Medium ``` format (have <pre> tag)\n",
    "        codeblocks_default = soup.find_all(\"pre\")\n",
    "\n",
    "        codeblock_raw = [code.text for code in codeblocks_default]\n",
    "        \n",
    "        codeblock_num = len(codeblocks_default)\n",
    "        \n",
    "        # Get a list of the number of lines of code of each code block\n",
    "        # Every code block has number of <br> + 1 lines\n",
    "            # <pre>\n",
    "            # ....\n",
    "            # <br>\n",
    "            # ....\n",
    "            # </pre>        \n",
    "        # Then compute basic statistics\n",
    "        \n",
    "        codeblock_lengths = [len(codeblock.find_all(\"br\"))+len(codeblock.find_all(\"span\")) for codeblock in codeblocks_default]\n",
    "        if len(codeblock_lengths) > 0:\n",
    "            codeblock_length_sum = sum(codeblock_lengths)\n",
    "            codeblock_length_median = statistics.median(codeblock_lengths)\n",
    "            codeblock_length_mean = statistics.mean(codeblock_lengths)\n",
    "            codeblock_length_min = min(codeblock_lengths)\n",
    "            codeblock_length_max = max(codeblock_lengths)\n",
    "        else:\n",
    "            codeblock_length_sum = 0\n",
    "            codeblock_length_median = 0\n",
    "            codeblock_length_mean = 0\n",
    "            codeblock_length_min = 0\n",
    "            codeblock_length_max = 0\n",
    "            \n",
    "            \n",
    "        # Extract number of <code> tags (inline code)\n",
    "        code_inline = soup.find_all(\"code\")\n",
    "        code_inline_raw = [code.text for code in code_inline]\n",
    "        code_inline_num = len(code_inline)\n",
    "\n",
    "            \n",
    "        # Extract num. Gist code blocks\n",
    "        # Gist code blocks have form <figure class=\"ab cd ef ... >\"\n",
    "        # <figure> is also used to wrap images in article have form: \n",
    "            # <figure class = \"ab cd ef ... paragraph-image\", so we exclude those figure elements\n",
    "\n",
    "            \n",
    "#         gists = soup.find_all(\"figure\")\n",
    "#         if len(gists)>0:\n",
    "#             code_gist_count = len([x for x in gists if x.attrs.get(\"class\") and \"paragraph-image\" not in x.attrs.get(\"class\")])\n",
    "#         else:\n",
    "#             code_gist_count = 0\n",
    "            \n",
    "                \n",
    "        # Extract a list of total links and their URLs\n",
    "        # We need to filter out Medium's internal links (share post, author profile, etc)\n",
    "        # These links contain the PostID, so we only collect <a> tags with href not containing PostID\n",
    "        links_all = soup.find_all(\"a\")\n",
    "        link_urls = [link.attrs.get('href') for link in links_all if str(data['PostID']) not in link.attrs.get('href')]\n",
    "        \n",
    "\n",
    "        # Extract total number of links\n",
    "        link_count = int(len(link_urls))\n",
    "        \n",
    "        # Extract number of highlights\n",
    "        highlights = soup.find_all(\"mark\")\n",
    "        highlight_count = int(len(highlights))\n",
    "\n",
    "        # Extract highlight text\n",
    "        highlights_text = [hlt.text for hlt in highlights]\n",
    "\n",
    "        # Extract image count\n",
    "        # A genuine image does not have alt (used for user logo), so we use this fact to verify image elements\n",
    "        # Get src and find number of unique URLs to find number of images\n",
    "#         imgli = soup.find_all(\"img\")\n",
    "#         newLi = [re.search(\"\\*.+(?![^\\.])\", img['src']).group(0).split(\".\", 1)[0] for img in imgli if (img.has_attr('src') and re.search(\"\\*.+(?![^\\.])\", img['src']) is not None)]\n",
    "#         if len(newLi) == 0:\n",
    "#             img_count = len(set([img.attrs['src'] for img in imgli if img.has_attr('src')]))\n",
    "#         else:\n",
    "#             img_count = len(set(newLi))-1\n",
    "    else:\n",
    "        text = np.NaN\n",
    "        word_count = np.NaN\n",
    "        code_count = np.NaN\n",
    "        img_count = np.NaN\n",
    "        featured_image = np.NaN\n",
    "        link_count = np.NaN\n",
    "        link_urls = np.NaN\n",
    "        highlights_text = np.NaN\n",
    "        highlight_count = np.NaN\n",
    "        code_inline_raw = np.NaN\n",
    "        code_inline_num = np.NaN\n",
    "        codeblock_raw = np.NaN\n",
    "        codeblock_num = np.NaN\n",
    "        codeblock_lengths = np.NaN\n",
    "        codeblock_length_sum = np.NaN\n",
    "        codeblock_length_median = np.NaN\n",
    "        codeblock_length_mean = np.NaN\n",
    "        codeblock_length_min = np.NaN\n",
    "        codeblock_length_max = np.NaN\n",
    "        \n",
    "    return text, word_count, featured_image, code_inline_raw, code_inline_num, codeblock_raw, codeblock_num, codeblock_lengths, codeblock_length_sum, codeblock_length_median, codeblock_length_mean, codeblock_length_min, codeblock_length_max, img_count, link_urls, link_count, highlights_text, highlight_count\n",
    "    \n",
    "# test = df\n",
    "# test[['Text', 'WordNum', 'HasFeaturedImage','CodeInlineRaw', 'CodeInlineNum', 'CodeBlockRaw', 'CodeBlockNum', \"CodeBlockLengthList\", \"CodeBlockLengthSum\", \"CodeBlockLengthMedian\", \"CodeBlockLengthMean\", \"CodeBlockLengthMin\", \"CodeBlockLengthMax\", 'ImgNum', 'LinkURLList', 'LinkNum', 'HLightTextList', 'HlightNum']] = df.apply(extract_features_from_html, axis=1, result_type=\"expand\")\n",
    "# del test['StoryHTML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(test.sample(1).to_html()))\n",
    "# display(HTML(test[test['PostID'] == 'e12a11dc4a4f'].to_html()))\n",
    "# display(HTML(test[test['HasFeaturedImage'] == False].to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate feature extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 rows read 80038 rows clean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "header = True\n",
    "\n",
    "numRows = 100000\n",
    "chunkSize = 10000\n",
    "\n",
    "processedRows = 0\n",
    "for data in pd.read_csv('data/df_story_chunk1.csv',encoding = 'ISO-8859-1', nrows=numRows, chunksize  = chunkSize, low_memory=False):\n",
    "    count += 1                          # counting the number of chunks\n",
    "    lastlen = len(data)                 # finding the length of last chunk\n",
    "\n",
    "    # Filter NaN PostID\n",
    "    data = data[-data['PostID'].isnull()]      \n",
    "    \n",
    "    # Filter NaN ResponseTime\n",
    "    data = data[-data['ReadingTime'].isnull()] \n",
    "\n",
    "    \n",
    "    # Filter stories posted after April 2020\n",
    "    data['PublishedDate'] = pd.to_datetime(data['PublishedDate']).dt.date\n",
    "    data = data[data['PublishedDate'] < pd.to_datetime(\"2020-04-01\")]\n",
    "\n",
    "    \n",
    "    # Convert responsetime \"X min read\" to X as int\n",
    "    data['ReadingTime'] = data['ReadingTime'].str.extract('(\\d+)', expand=False).astype(int) \n",
    "    \n",
    "    # Get number of tags used\n",
    "    data['TagSum'] = data[['Tag1','Tag2','Tag3','Tag4', 'Tag5']].notnull().sum(axis=1)\n",
    "\n",
    "    # Extract features  from HTML\n",
    "    data[['Text', 'WordNum', 'HasFeaturedImage','CodeInlineRaw', 'CodeInlineNum', 'CodeBlockRaw', 'CodeBlockNum', \"CodeBlockLengthList\", \"CodeBlockLengthSum\", \"CodeBlockLengthMedian\", \"CodeBlockLengthMean\", \"CodeBlockLengthMin\", \"CodeBlockLengthMax\", 'ImgNum', 'LinkURLList', 'LinkNum', 'HLightTextList', 'HlightNum']] = data.apply(extract_features_from_html, axis=1, result_type=\"expand\")\n",
    "    \n",
    "    # Delete raw html\n",
    "    del data['StoryHTML']\n",
    "    \n",
    "    processedRows += len(data)\n",
    "    \n",
    "    data.to_csv(\"data/df_story_features.csv\", header=header, mode=\"a\")\n",
    "    header = False\n",
    "datalength = (count*chunkSize + lastlen - chunkSize) # length of total file\n",
    "print(datalength, \"rows read\", processedRows, \"rows clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2020-02-04\n",
       "1       2018-12-31\n",
       "2       2018-12-31\n",
       "3       2019-12-31\n",
       "4       2016-12-30\n",
       "           ...    \n",
       "2220    2018-12-10\n",
       "2221    2018-12-10\n",
       "2222    2018-12-10\n",
       "2223    2018-12-10\n",
       "2224    2018-12-01\n",
       "Name: PublishedDate, Length: 2225, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/df_story_features.csv\")\n",
    "# display(HTML(test.head().to_html()))\n",
    "\n",
    "display(test['PublishedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_html = df.iloc[547].StoryHTML\n",
    "testsoup = BeautifulSoup(test_html, 'lxml')\n",
    "print(testsoup.find_all(\"figure\", {'class':re.compile(\"/.*[^image]$/\")}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545    https://medium.com/dataform/sending-data-from-bigquery-to-intercom-using-google-cloud-functions-c65f26906a4?source=tag_archive---------2-----------------------\n",
      "546    https://medium.com/datadriveninvestor/java-enums-what-a-special-type-276d27423a71?source=tag_archive---------0-----------------------                          \n"
     ]
    }
   ],
   "source": [
    "# display(HTML(df.head(5).to_html()))\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print(df[df['CodeNum']>0].head(100)['StoryURL'].to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.057077070026525\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(df[df['CodeBlockLengthMean']>0]['CodeBlockLengthMean'].mean())\n",
    "df['CodeBlockLengthMean'].hist(bins=60)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
